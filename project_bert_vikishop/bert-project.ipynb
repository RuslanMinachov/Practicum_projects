{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0676616f",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "**Классификация токсичных комментариев с использованием BERT**\n",
    "\n",
    "_________\n",
    "\n",
    "**Описание проекта.**\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис, позволяющий пользователям редактировать и дополнять описания товаров в стиле вики-сообществ. Клиенты могут предлагать правки и комментировать изменения других пользователей. Для обеспечения качества контента требуется инструмент, который автоматически выявляет токсичные комментарии и отправляет их на модерацию. Цель проекта — разработать модель машинного обучения для классификации комментариев на позитивные и негативные с метрикой качества F1 не менее 0.75. В проекте используется предобученная модель BERT для создания эмбеддингов текстов, а также различные алгоритмы машинного обучения для классификации.\n",
    "\n",
    "__________\n",
    "\n",
    "**Задачи проекта.**\n",
    "\n",
    "1. Загрузить и изучить данные из файла `toxic_comments.csv`.\n",
    "2. Выполнить предобработку текстовых данных, включая токенизацию и создание эмбеддингов с использованием модели BERT.\n",
    "3. Подготовить данные для обучения моделей.\n",
    "5. Обучить и сравнить несколько моделей машинного обучения.\n",
    "6. Выбрать лучшую модель на основе метрики F1 и протестировать её на тестовой выборке.\n",
    "7. Сформулировать итоговые выводы.\n",
    "\n",
    "____________\n",
    "\n",
    "**Исходные данные.**\n",
    "\n",
    "Данные находятся в файле `/datasets/toxic_comments.csv`.  \n",
    "- Столбец `text`: текст комментария.  \n",
    "- Столбец `toxic`: целевой признак (0 — позитивный, 1 — токсичный).  \n",
    "\n",
    "____________\n",
    "\n",
    "**Данное исследование разделим на несколько частей.**\n",
    "\n",
    "- [**Шаг 1. Загрузка и изучение данных.**](#section1)\n",
    "\n",
    "- [**Шаг 2. Создание эмбедингов.**](#section2)\n",
    "  \n",
    "- [**Шаг 3. Обучение моделей.**](#section3)\n",
    "\n",
    "- [**Шаг 4. Итоговый вывод.**](#section4)\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d3aae0-cd00-4628-8db9-013f6238bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f7e25-75a9-447e-b9f8-4fe0ebcc40f6",
   "metadata": {},
   "source": [
    "# Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f54665-2043-4d84-b8f0-210f801a9961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_tweets loaded with shape: (159292, 3)\n"
     ]
    }
   ],
   "source": [
    "df_pth1 = '/Users/ruslanminacov/Downloads/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(df_pth1):\n",
    "    df_tweets = pd.read_csv(df_pth1)\n",
    "else:\n",
    "    print('Something is wrong with toxic_comments.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'df_tweets' in locals():\n",
    "    print(f\"df_tweets loaded with shape: {df_tweets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff11822-96e2-4d0d-8610-8dae5ade94cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eafc2b7e-b2b8-4000-bd5f-9565910c332b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374a108-0697-429f-8781-7b17ad7d7ac6",
   "metadata": {},
   "source": [
    "**Промежуточный вывод:**\n",
    "\n",
    "1. **Успешная загрузка данных**:\n",
    "   - Датасет загружен с использованием библиотеки `pandas` из файла.\n",
    "   - Проверка существования файла выполнена успешно, ошибок при загрузке не возникло.\n",
    "\n",
    "2. **Характеристики датасета**:\n",
    "   - Датасет `df_tweets` содержит **159292 строки** и **3 столбца**:\n",
    "     - `Unnamed: 0`: индекс (тип данных — `int64`).\n",
    "     - `text`: текст комментариев (тип данных — `object`, строка).\n",
    "     - `toxic`: метка токсичности (тип данных — `int64`, бинарная переменная).\n",
    "   - Все столбцы не содержат пропущенных значений (`Non-Null Count: 159292` для каждого столбца).\n",
    "   - Объем памяти, занимаемый датасетом, составляет около **3.6+ МБ**.\n",
    "\n",
    "3. **Предварительный просмотр данных**:\n",
    "   - Первые пять строк датасета показывают, что столбец `text` содержит текстовые комментарии, а столбец `toxic` имеет значение `0` (нетоксичные комментарии) для этих примеров.\n",
    "   - Столбец `Unnamed: 0` является техническим индексом и, вероятно, не несет полезной информации для анализа.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba151c6-11f8-4597-b687-ac4ca9764685",
   "metadata": {},
   "source": [
    "# Создание эмбедингов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019489ec-6bc1-4aa3-9904-0bf0cee261d1",
   "metadata": {},
   "source": [
    "Для токенизации и создании эмбедингов выберем модель 'unitary/toxic-bert', данная модель уже предобучена для определения токсичных комментариев. Процесс создания эмбедингов запустим на GPU для меньшей затраты времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c2ac4c-a783-4ed0-9adf-636783566fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "model = transformers.BertModel.from_pretrained('unitary/toxic-bert')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d69baa-14aa-422e-b064-9d1e7f7b41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df_tweets['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))\n",
    "\n",
    "\n",
    "max_len = max(len(i) for i in tokenized.values)\n",
    "\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e0fd4f-207c-4e63-bec9-62a417e15c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869c3973d0f145cea63130201699dc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "model.eval()\n",
    "for i in notebook.tqdm(range(0, padded.shape[0], batch_size)):\n",
    "    batch = torch.LongTensor(padded[i:i+batch_size]).to(device)\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[i:i+batch_size]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    \n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "\n",
    "\n",
    "features = np.concatenate(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a3751",
   "metadata": {},
   "source": [
    "features_df = pd.DataFrame(features)\n",
    "features_df.to_csv('toxic_features_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f7301",
   "metadata": {},
   "source": [
    "features_df = pd.read_csv('toxic_features_en.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0163d9d",
   "metadata": {},
   "source": [
    "Для обучения моделий дополнительно созданим валидационную выборку(вместо использования метода cross_val_score) в целях экономии ресурсов. Разделим данные на выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a2d60c-bbd9-4663-9518-5752165fdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(features_df, df_tweets['toxic'], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef50f7f",
   "metadata": {},
   "source": [
    "**Промежуточный вывод**\n",
    "\n",
    "1. Создание эмбеддингов\n",
    "- **Выбор модели**: Использована предобученная модель `unitary/toxic-bert`, оптимизированная для определения токсичных комментариев.\n",
    "- **Токенизация**:\n",
    "  - Применен `BertTokenizer` с максимальной длиной последовательности 512 токенов.\n",
    "  - Учтены специальные токены и применено усечение (truncation) для длинных текстов.\n",
    "- **Ускорение вычислений**:\n",
    "  - Процесс выполнен на GPU (при наличии) для оптимизации времени.\n",
    "  - Модель переведена в режим оценки (`model.eval()`) для исключения вычисления градиентов.\n",
    "- **Обработка данных**:\n",
    "  - Токенизированные последовательности дополнены (padding) до максимальной длины.\n",
    "  - Созданы маски внимания (attention masks) для учета реальных токенов.\n",
    "  - Эмбеддинги извлечены батчами (размер батча — 100).\n",
    "- **Результат**:\n",
    "  - Полученные эмбеддинги объединены в массив `features`.\n",
    "\n",
    "2. Подготовка данных для обучения\n",
    "- **Разделение выборок**:\n",
    "  - Данные разделены на тренировочную+валидационную (`X_train_val`, 80%) и тестовую (`X_test`, 20%) с `random_state=42` для воспроизводимости.\n",
    "  - Из `X_train_val` выделены тренировочная (`X_train`, 80%) и валидационная (`X_val`, 20%) выборки.\n",
    "  - Целевая переменная `toxic` разделена на `y_train`, `y_val` и `y_test` соответственно.\n",
    "- **Цель**:\n",
    "  - Экономия ресурсов за счет использования валидационной выборки вместо кросс-валидации.\n",
    "  - Обеспечение воспроизводимости и структурированности данных для последующего обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe3e9c",
   "metadata": {},
   "source": [
    "# Обучение моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5b542",
   "metadata": {},
   "source": [
    "## Модель LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a14139-3c8a-4912-925a-4ac5443db9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    C = trial.suggest_float(\"C\", 1e-5, 1e2, log=True)\n",
    "    solver = trial.suggest_categorical(\"solver\", [\"lbfgs\", \"liblinear\", \"saga\"])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 1000)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]) if solver in [\"liblinear\", \"saga\"] else \"l2\"\n",
    "\n",
    "    \n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        penalty=penalty,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    f1_val = f1_score(y_val, y_pred)\n",
    "\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1010e0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-10 20:16:30,540] A new study created in memory with name: no-name-dbbf58ba-9ddd-4163-afd2-9931d1302b57\n",
      "[I 2025-07-10 20:16:51,997] Trial 0 finished with value: 0.9502912621359223 and parameters: {'C': 0.05949001406067821, 'solver': 'liblinear', 'max_iter': 857, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:16:53,866] Trial 1 finished with value: 0.9414566382218694 and parameters: {'C': 2.5636704145768908e-05, 'solver': 'lbfgs', 'max_iter': 870}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:17:02,872] Trial 2 finished with value: 0.9451279047061121 and parameters: {'C': 0.00010818672273001525, 'solver': 'liblinear', 'max_iter': 692, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "/opt/anaconda3/envs/practicum/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-10 20:18:22,387] Trial 3 finished with value: 0.9489221208001554 and parameters: {'C': 0.002311309330502211, 'solver': 'saga', 'max_iter': 121, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:21:13,935] Trial 4 finished with value: 0.9484936831875608 and parameters: {'C': 0.06361900309458643, 'solver': 'saga', 'max_iter': 903, 'penalty': 'l1'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:27:56,119] Trial 5 finished with value: 0.9477365455605207 and parameters: {'C': 0.7700493298926568, 'solver': 'saga', 'max_iter': 989, 'penalty': 'l1'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:30:40,498] Trial 6 finished with value: 0.9485536788973015 and parameters: {'C': 0.23348859798647106, 'solver': 'saga', 'max_iter': 462, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:30:45,963] Trial 7 finished with value: 0.9489419530188313 and parameters: {'C': 76.71183575690998, 'solver': 'lbfgs', 'max_iter': 729}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:30:48,602] Trial 8 finished with value: 0.9494753206373883 and parameters: {'C': 0.019084666040793907, 'solver': 'lbfgs', 'max_iter': 310}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:31:02,578] Trial 9 finished with value: 0.9451921201482348 and parameters: {'C': 0.00013365208384192765, 'solver': 'saga', 'max_iter': 228, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:32:17,035] Trial 10 finished with value: 0.9444985394352483 and parameters: {'C': 7.362208533048399, 'solver': 'liblinear', 'max_iter': 561, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:32:19,292] Trial 11 finished with value: 0.9496598639455782 and parameters: {'C': 0.004972821345467508, 'solver': 'lbfgs', 'max_iter': 350}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:32:28,014] Trial 12 finished with value: 0.9444552718768271 and parameters: {'C': 0.00598235784861607, 'solver': 'liblinear', 'max_iter': 426, 'penalty': 'l1'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:32:40,327] Trial 13 finished with value: 0.9473275024295432 and parameters: {'C': 0.0007465989797898033, 'solver': 'liblinear', 'max_iter': 639, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:32:45,682] Trial 14 finished with value: 0.9489221208001554 and parameters: {'C': 0.5451831666726423, 'solver': 'lbfgs', 'max_iter': 364}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:32:52,699] Trial 15 finished with value: 0.9482892690513219 and parameters: {'C': 0.025702851366725975, 'solver': 'liblinear', 'max_iter': 782, 'penalty': 'l1'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:32:54,723] Trial 16 finished with value: 0.948309366498251 and parameters: {'C': 0.0011821745952242816, 'solver': 'lbfgs', 'max_iter': 537}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:33:59,692] Trial 17 finished with value: 0.9449309204125316 and parameters: {'C': 3.842206507025965, 'solver': 'liblinear', 'max_iter': 219, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:34:02,648] Trial 18 finished with value: 0.9496794249077132 and parameters: {'C': 0.12527379987592635, 'solver': 'lbfgs', 'max_iter': 582}. Best is trial 0 with value: 0.9502912621359223.\n",
      "[I 2025-07-10 20:34:30,226] Trial 19 finished with value: 0.9499223602484472 and parameters: {'C': 0.08024637366903863, 'solver': 'liblinear', 'max_iter': 994, 'penalty': 'l2'}. Best is trial 0 with value: 0.9502912621359223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'C': 0.05949001406067821, 'solver': 'liblinear', 'max_iter': 857, 'penalty': 'l2'}\n",
      "Лучшая точность:  0.9502912621359223\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  \n",
    "\n",
    "# Вывод лучших гиперпараметров\n",
    "print(\"Лучшие гиперпараметры: \", study.best_params)\n",
    "print(\"Лучшая точность: \", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f89df3-7cda-4abd-83e8-0fb2a4f37ab0",
   "metadata": {},
   "source": [
    "- Лучшие гиперпараметры:  {'C': 0.05949001406067821, 'solver': 'liblinear', 'max_iter': 857, 'penalty': 'l2'}\n",
    "- Лучшая точность:  0.9502912621359223"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf2ab32",
   "metadata": {},
   "source": [
    "## Модель LGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df472650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Определение гиперпараметра для SelectKBest\n",
    "    k = trial.suggest_int('k', 1, 100)  # Количество признаков от 1 до числа всех признаков\n",
    "\n",
    "    # Отбор признаков с помощью SelectKBest\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_val_selected = selector.transform(X_val)\n",
    "   \n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.3, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'objective': 'binary',  # Для бинарной классификации\n",
    "        'verbose': -1  # Отключение вывода логов\n",
    "    }\n",
    "\n",
    "    # Создание модели LightGBM\n",
    "    model = LGBMClassifier(**params)\n",
    "\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val_selected)\n",
    "    f1_val = f1_score(y_val, y_pred)\n",
    "\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d3f5fbc-98b1-4ec3-bce2-5dab9fde0948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 14:20:25,786] A new study created in memory with name: no-name-6affb8d3-af97-43e9-8a53-500fa4b8ad74\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:27,580] Trial 0 finished with value: 0.9424530129819803 and parameters: {'k': 15, 'num_leaves': 93, 'learning_rate': 0.07230204885121799, 'n_estimators': 434, 'max_depth': 4, 'min_child_samples': 65, 'subsample': 0.5291354198890934, 'colsample_bytree': 0.959068869609087, 'reg_alpha': 2.3965811067074557e-05, 'reg_lambda': 4.365473702889757}. Best is trial 0 with value: 0.9424530129819803.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:30,051] Trial 1 finished with value: 0.7777251184834123 and parameters: {'k': 76, 'num_leaves': 70, 'learning_rate': 0.0025774810581655023, 'n_estimators': 234, 'max_depth': 10, 'min_child_samples': 23, 'subsample': 0.5550618288527975, 'colsample_bytree': 0.9859021848741116, 'reg_alpha': 7.05222596704663, 'reg_lambda': 4.585174142611061e-05}. Best is trial 0 with value: 0.9424530129819803.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:31,685] Trial 2 finished with value: 0.9455109559821602 and parameters: {'k': 19, 'num_leaves': 44, 'learning_rate': 0.06899515688884936, 'n_estimators': 220, 'max_depth': 12, 'min_child_samples': 51, 'subsample': 0.8381737465114012, 'colsample_bytree': 0.76101604978953, 'reg_alpha': 0.009155199333907961, 'reg_lambda': 0.00489657874919882}. Best is trial 2 with value: 0.9455109559821602.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:34,440] Trial 3 finished with value: 0.0 and parameters: {'k': 67, 'num_leaves': 61, 'learning_rate': 0.000716688775309724, 'n_estimators': 480, 'max_depth': 5, 'min_child_samples': 69, 'subsample': 0.7635676231694821, 'colsample_bytree': 0.8323191154318903, 'reg_alpha': 1.0880450647465367, 'reg_lambda': 0.12591215288421506}. Best is trial 2 with value: 0.9455109559821602.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:36,894] Trial 4 finished with value: 0.9430957467469412 and parameters: {'k': 69, 'num_leaves': 72, 'learning_rate': 0.17665623389336502, 'n_estimators': 411, 'max_depth': 5, 'min_child_samples': 83, 'subsample': 0.8159277793441639, 'colsample_bytree': 0.7504904200321263, 'reg_alpha': 0.5574982700244967, 'reg_lambda': 0.0007195107439714014}. Best is trial 2 with value: 0.9455109559821602.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:38,457] Trial 5 finished with value: 0.0 and parameters: {'k': 2, 'num_leaves': 56, 'learning_rate': 0.00010367657683007766, 'n_estimators': 404, 'max_depth': 6, 'min_child_samples': 19, 'subsample': 0.9067200098942558, 'colsample_bytree': 0.9678992202906852, 'reg_alpha': 0.02673292073367179, 'reg_lambda': 3.498547064768873e-05}. Best is trial 2 with value: 0.9455109559821602.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:40,649] Trial 6 finished with value: 0.0 and parameters: {'k': 77, 'num_leaves': 139, 'learning_rate': 0.002407878943244025, 'n_estimators': 233, 'max_depth': 5, 'min_child_samples': 28, 'subsample': 0.5060829461192174, 'colsample_bytree': 0.9286251501182972, 'reg_alpha': 7.5917541512000195, 'reg_lambda': 1.3910772622516875e-05}. Best is trial 2 with value: 0.9455109559821602.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:42,409] Trial 7 finished with value: 0.9419755482243354 and parameters: {'k': 24, 'num_leaves': 86, 'learning_rate': 0.2491891493431021, 'n_estimators': 232, 'max_depth': 10, 'min_child_samples': 96, 'subsample': 0.9392802784236405, 'colsample_bytree': 0.6736288481452954, 'reg_alpha': 0.001203976641216919, 'reg_lambda': 0.04277552077773775}. Best is trial 2 with value: 0.9455109559821602.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:43,774] Trial 8 finished with value: 0.0 and parameters: {'k': 36, 'num_leaves': 70, 'learning_rate': 0.0038948973847101197, 'n_estimators': 60, 'max_depth': 12, 'min_child_samples': 42, 'subsample': 0.7764053332634624, 'colsample_bytree': 0.7478670722866229, 'reg_alpha': 0.018034161202916014, 'reg_lambda': 1.8534279286362663}. Best is trial 2 with value: 0.9455109559821602.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:45,430] Trial 9 finished with value: 0.9460613116026387 and parameters: {'k': 70, 'num_leaves': 106, 'learning_rate': 0.052138658197426926, 'n_estimators': 104, 'max_depth': 4, 'min_child_samples': 61, 'subsample': 0.8235887206533512, 'colsample_bytree': 0.9195570150453197, 'reg_alpha': 2.731147689114286, 'reg_lambda': 0.48938269395832074}. Best is trial 9 with value: 0.9460613116026387.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:47,126] Trial 10 finished with value: 0.9417341497136086 and parameters: {'k': 97, 'num_leaves': 120, 'learning_rate': 0.01999597625847021, 'n_estimators': 70, 'max_depth': 3, 'min_child_samples': 43, 'subsample': 0.6524513979493549, 'colsample_bytree': 0.5033323453496314, 'reg_alpha': 2.5405704314929764e-05, 'reg_lambda': 0.30218773885578337}. Best is trial 9 with value: 0.9460613116026387.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:48,785] Trial 11 finished with value: 0.9462866007368625 and parameters: {'k': 45, 'num_leaves': 25, 'learning_rate': 0.036469532932803236, 'n_estimators': 128, 'max_depth': 8, 'min_child_samples': 50, 'subsample': 0.8657895062886577, 'colsample_bytree': 0.852683440456163, 'reg_alpha': 0.0008844359912102507, 'reg_lambda': 0.002530717273014435}. Best is trial 11 with value: 0.9462866007368625.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:50,463] Trial 12 finished with value: 0.9456669912366115 and parameters: {'k': 49, 'num_leaves': 31, 'learning_rate': 0.01876885785755142, 'n_estimators': 139, 'max_depth': 8, 'min_child_samples': 66, 'subsample': 0.9844953012952758, 'colsample_bytree': 0.8658215287800604, 'reg_alpha': 0.0004556789877525956, 'reg_lambda': 0.0009672469476734355}. Best is trial 11 with value: 0.9462866007368625.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:52,381] Trial 13 finished with value: 0.9465084613888348 and parameters: {'k': 51, 'num_leaves': 105, 'learning_rate': 0.019587742591611713, 'n_estimators': 149, 'max_depth': 7, 'min_child_samples': 37, 'subsample': 0.6759945458571511, 'colsample_bytree': 0.8635720574448441, 'reg_alpha': 0.0006092989614574926, 'reg_lambda': 0.011564088326103212}. Best is trial 13 with value: 0.9465084613888348.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:54,543] Trial 14 finished with value: 0.946320515323053 and parameters: {'k': 50, 'num_leaves': 123, 'learning_rate': 0.014828131776540101, 'n_estimators': 156, 'max_depth': 8, 'min_child_samples': 34, 'subsample': 0.6348332839340876, 'colsample_bytree': 0.8579709171641898, 'reg_alpha': 0.0003868408631238588, 'reg_lambda': 0.011018643211189354}. Best is trial 13 with value: 0.9465084613888348.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:20:57,764] Trial 15 finished with value: 0.9478599221789883 and parameters: {'k': 57, 'num_leaves': 148, 'learning_rate': 0.009978103296293521, 'n_estimators': 338, 'max_depth': 9, 'min_child_samples': 35, 'subsample': 0.66636025464634, 'colsample_bytree': 0.6498760983199332, 'reg_alpha': 0.00014957828627846294, 'reg_lambda': 0.024589531212131692}. Best is trial 15 with value: 0.9478599221789883.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:21:00,344] Trial 16 finished with value: 0.9445745511319282 and parameters: {'k': 36, 'num_leaves': 147, 'learning_rate': 0.007847433660609353, 'n_estimators': 334, 'max_depth': 10, 'min_child_samples': 11, 'subsample': 0.6909380032040375, 'colsample_bytree': 0.5929282948412475, 'reg_alpha': 5.791856154843989e-05, 'reg_lambda': 0.031713898261746865}. Best is trial 15 with value: 0.9478599221789883.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:21:02,749] Trial 17 finished with value: 0.0 and parameters: {'k': 58, 'num_leaves': 133, 'learning_rate': 0.0014192057414861576, 'n_estimators': 291, 'max_depth': 7, 'min_child_samples': 34, 'subsample': 0.701647275914009, 'colsample_bytree': 0.6284146876033063, 'reg_alpha': 9.419329397363169e-05, 'reg_lambda': 0.00023382037387180738}. Best is trial 15 with value: 0.9478599221789883.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:21:06,603] Trial 18 finished with value: 0.0 and parameters: {'k': 90, 'num_leaves': 105, 'learning_rate': 0.0004124194137659465, 'n_estimators': 347, 'max_depth': 9, 'min_child_samples': 41, 'subsample': 0.5948421731972273, 'colsample_bytree': 0.6834105433314372, 'reg_alpha': 0.004715851633096449, 'reg_lambda': 0.02312833871631204}. Best is trial 15 with value: 0.9478599221789883.\n",
      "D:\\anaconda3\\envs\\practicum_new\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-07-11 14:21:08,530] Trial 19 finished with value: 0.944136291600634 and parameters: {'k': 58, 'num_leaves': 107, 'learning_rate': 0.007468302237890934, 'n_estimators': 183, 'max_depth': 7, 'min_child_samples': 15, 'subsample': 0.7113206269013838, 'colsample_bytree': 0.5684457435942813, 'reg_alpha': 0.11336982900459479, 'reg_lambda': 0.11290818146219095}. Best is trial 15 with value: 0.9478599221789883.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'k': 57, 'num_leaves': 148, 'learning_rate': 0.009978103296293521, 'n_estimators': 338, 'max_depth': 9, 'min_child_samples': 35, 'subsample': 0.66636025464634, 'colsample_bytree': 0.6498760983199332, 'reg_alpha': 0.00014957828627846294, 'reg_lambda': 0.024589531212131692}\n",
      "Лучшая точность:  0.9478599221789883\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  \n",
    "\n",
    "# Вывод лучших гиперпараметров\n",
    "print(\"Лучшие гиперпараметры: \", study.best_params)\n",
    "print(\"Лучшая точность: \", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad9814-e573-431f-baf0-e7f2995099cf",
   "metadata": {},
   "source": [
    "- Лучшие гиперпараметры:  {'k': 57, 'num_leaves': 148, 'learning_rate': 0.009978103296293521, 'n_estimators': 338, 'max_depth': 9, 'min_child_samples': 35, 'subsample': 0.66636025464634, 'colsample_bytree': 0.6498760983199332, 'reg_alpha': 0.00014957828627846294, 'reg_lambda': 0.024589531212131692}\n",
    "- Лучшая точность:  0.9478599221789883"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796ac5c-178a-4e18-a813-30a1ecf0c8c8",
   "metadata": {},
   "source": [
    "## Моедль SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0412ae4b-27f3-41eb-9f3b-d585e898d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    k = trial.suggest_int('k', 1, 100)  # Количество признаков от 1 до числа всех признаков\n",
    "\n",
    "    # Отбор признаков с помощью SelectKBest\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_val_selected = selector.transform(X_val)\n",
    "    \n",
    "    # Определение пространства гиперпараметров\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)  # Параметр регуляризации\n",
    "    gamma = trial.suggest_float('gamma', 1e-4, 1e1, log=True) if kernel in ['rbf', 'poly'] else 'scale'\n",
    "    \n",
    "    # Создание модели SVC\n",
    "    svc = SVC(\n",
    "        kernel=kernel,\n",
    "        C=C,\n",
    "        gamma=gamma,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Обучение модели\n",
    "    svc.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Предсказание и оценка точности\n",
    "    y_pred = svc.predict(X_val_selected)\n",
    "    f1_val = f1_score(y_val, y_pred)\n",
    "\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df74d1a6-fd5e-4a4e-b65d-0680f264e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 14:44:16,217] A new study created in memory with name: no-name-6d88634b-fdca-46ae-bed0-81002f89daf0\n",
      "[I 2025-07-11 14:44:39,608] Trial 0 finished with value: 0.9152911300562308 and parameters: {'k': 29, 'kernel': 'poly', 'C': 0.27292658642248574, 'gamma': 0.015946968983812336}. Best is trial 0 with value: 0.9152911300562308.\n",
      "[I 2025-07-11 14:48:23,409] Trial 1 finished with value: 0.0 and parameters: {'k': 88, 'kernel': 'poly', 'C': 0.019483400400456416, 'gamma': 0.001473230257510029}. Best is trial 0 with value: 0.9152911300562308.\n",
      "[I 2025-07-11 14:48:40,135] Trial 2 finished with value: 0.945751506902586 and parameters: {'k': 27, 'kernel': 'rbf', 'C': 517.6134188749666, 'gamma': 0.00016151925176029224}. Best is trial 2 with value: 0.945751506902586.\n",
      "[I 2025-07-11 14:48:51,723] Trial 3 finished with value: 0.9435280419173298 and parameters: {'k': 36, 'kernel': 'poly', 'C': 4.113811044455932, 'gamma': 0.03585941342895871}. Best is trial 2 with value: 0.945751506902586.\n",
      "[I 2025-07-11 14:51:01,090] Trial 4 finished with value: 0.6201716738197425 and parameters: {'k': 41, 'kernel': 'poly', 'C': 0.6247324413109587, 'gamma': 0.0018999728139222466}. Best is trial 2 with value: 0.945751506902586.\n",
      "[I 2025-07-11 14:52:00,812] Trial 5 finished with value: 0.9441545893719807 and parameters: {'k': 65, 'kernel': 'rbf', 'C': 0.10182238851394428, 'gamma': 0.3819526666210075}. Best is trial 2 with value: 0.945751506902586.\n",
      "[I 2025-07-11 14:52:08,723] Trial 6 finished with value: 0.941907907518943 and parameters: {'k': 12, 'kernel': 'poly', 'C': 0.007439357442415772, 'gamma': 1.4050479738997677}. Best is trial 2 with value: 0.945751506902586.\n",
      "[I 2025-07-11 14:52:31,177] Trial 7 finished with value: 0.9444121634708503 and parameters: {'k': 65, 'kernel': 'rbf', 'C': 0.13977865912945436, 'gamma': 0.08820850567057893}. Best is trial 2 with value: 0.945751506902586.\n",
      "[I 2025-07-11 15:02:50,104] Trial 8 finished with value: 0.9447685725398678 and parameters: {'k': 25, 'kernel': 'linear', 'C': 503.5215883306455}. Best is trial 2 with value: 0.945751506902586.\n",
      "[I 2025-07-11 15:03:09,067] Trial 9 finished with value: 0.9469593938216436 and parameters: {'k': 84, 'kernel': 'linear', 'C': 0.006479168843764122}. Best is trial 9 with value: 0.9469593938216436.\n",
      "[I 2025-07-11 15:03:31,078] Trial 10 finished with value: 0.9460613116026387 and parameters: {'k': 98, 'kernel': 'linear', 'C': 0.0011102027442808449}. Best is trial 9 with value: 0.9469593938216436.\n",
      "[I 2025-07-11 15:03:53,646] Trial 11 finished with value: 0.9458777885548012 and parameters: {'k': 99, 'kernel': 'linear', 'C': 0.0012645705293674655}. Best is trial 9 with value: 0.9469593938216436.\n",
      "[I 2025-07-11 15:04:15,842] Trial 12 finished with value: 0.9458777885548012 and parameters: {'k': 79, 'kernel': 'linear', 'C': 0.0011365373194794812}. Best is trial 9 with value: 0.9469593938216436.\n",
      "[I 2025-07-11 15:06:11,524] Trial 13 finished with value: 0.9460564751703993 and parameters: {'k': 100, 'kernel': 'linear', 'C': 7.639753583179734}. Best is trial 9 with value: 0.9469593938216436.\n",
      "[I 2025-07-11 15:06:30,577] Trial 14 finished with value: 0.9461194320171173 and parameters: {'k': 75, 'kernel': 'linear', 'C': 0.007817488589685773}. Best is trial 9 with value: 0.9469593938216436.\n",
      "[I 2025-07-11 15:06:45,712] Trial 15 finished with value: 0.9477162293488824 and parameters: {'k': 64, 'kernel': 'linear', 'C': 0.02673525271482263}. Best is trial 15 with value: 0.9477162293488824.\n",
      "[I 2025-07-11 15:07:00,142] Trial 16 finished with value: 0.9468167701863354 and parameters: {'k': 56, 'kernel': 'linear', 'C': 0.03255065882584375}. Best is trial 15 with value: 0.9477162293488824.\n",
      "[I 2025-07-11 15:07:54,261] Trial 17 finished with value: 0.9461613216715258 and parameters: {'k': 82, 'kernel': 'linear', 'C': 3.834459407612209}. Best is trial 15 with value: 0.9477162293488824.\n",
      "[I 2025-07-11 15:08:08,943] Trial 18 finished with value: 0.9465915711788697 and parameters: {'k': 56, 'kernel': 'linear', 'C': 0.007864649151699585}. Best is trial 15 with value: 0.9477162293488824.\n",
      "[I 2025-07-11 15:16:31,195] Trial 19 finished with value: 0.9445417396380619 and parameters: {'k': 69, 'kernel': 'linear', 'C': 73.00665659803536}. Best is trial 15 with value: 0.9477162293488824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры:  {'k': 64, 'kernel': 'linear', 'C': 0.02673525271482263}\n",
      "Лучшая точность:  0.9477162293488824\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  \n",
    "\n",
    "# Вывод лучших гиперпараметров\n",
    "print(\"Лучшие гиперпараметры: \", study.best_params)\n",
    "print(\"Лучшая точность: \", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7414f-0e4a-4dd7-ae8d-a43d9157d383",
   "metadata": {},
   "source": [
    "- Лучшие гиперпараметры:  {'k': 64, 'kernel': 'linear', 'C': 0.02673525271482263}\n",
    "- Лучшая точность:  0.9477162293488824"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14b0cc",
   "metadata": {},
   "source": [
    "## Выбор модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01866e88",
   "metadata": {},
   "source": [
    "Лучший показатель метрики `f1` выдала модель `LogisticRegression` c параметрами `'C': 0.05949001406067821, 'solver': 'liblinear', 'max_iter': 857, 'penalty': 'l2'`. Протестируем данную модель на тестовой выборке: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8dc60b2-fd58-410b-be55-e17eac062505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = LogisticRegression(\n",
    "        C=0.05949001406067821,\n",
    "        solver='liblinear',\n",
    "        penalty='l2',\n",
    "        max_iter=857,\n",
    "        random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793aad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 модели на тестовой выборке: 0.9503435352904435\n"
     ]
    }
   ],
   "source": [
    "model_test.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_test.predict(X_test)\n",
    "f1_test = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'f1 модели на тестовой выборке: {f1_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc360f5",
   "metadata": {},
   "source": [
    "**Промежуточный вывод**\n",
    "\n",
    "**1. Модель LogisticRegression**\n",
    "- **Подход**:\n",
    "  - Использована логистическая регрессия с оптимизацией гиперпараметров через библиотеку Optuna.\n",
    "  - Настраиваемые параметры:\n",
    "    - `C`: регуляризация (диапазон: 1e-5–1e2).\n",
    "    - `solver`: оптимизаторы (`lbfgs`, `liblinear`, `saga`).\n",
    "    - `max_iter`: максимальное количество итераций (100–1000).\n",
    "    - `penalty`: тип регуляризации (`l1`, `l2`, в зависимости от `solver`).\n",
    "  - Проведено 20 испытаний с метрикой F1 для максимизации качества на валидационной выборке.\n",
    "- **Результаты**:\n",
    "  - Лучшие гиперпараметры: `C=0.05949`, `solver='liblinear'`, `max_iter=857`, `penalty='l2'`.\n",
    "  - Лучшая F1-метрика на валидационной выборке: **0.95029**.\n",
    "  \n",
    "\n",
    "**2. Модель LightGBM**\n",
    "- **Подход**:\n",
    "  - Использован градиентный бустинг (LGBMClassifier) с отбором признаков через `SelectKBest` (параметр `k` от 1 до 100).\n",
    "  - Оптимизированы гиперпараметры с помощью Optuna (20 испытаний):\n",
    "    - `num_leaves`, `learning_rate`, `n_estimators`, `max_depth`, `min_child_samples`, `subsample`, `colsample_bytree`, `reg_alpha`, `reg_lambda`.\n",
    "  - Целевая метрика: F1 на валидационной выборке.\n",
    "- **Результаты**:\n",
    "  - Лучшие гиперпараметры: `k=57`, `num_leaves=148`, `learning_rate=0.00998`, `n_estimators=338`, `max_depth=9`, `min_child_samples=35`, `subsample=0.666`, `colsample_bytree=0.650`, `reg_alpha=0.00015`, `reg_lambda=0.0246`.\n",
    "  - Лучшая F1-метрика на валидационной выборке: **0.94786**.\n",
    " \n",
    "**3. Модель SVC**\n",
    "- **Подход**:\n",
    "  - Применен метод опорных векторов (SVC) с отбором признаков через `SelectKBest` (параметр `k` от 1 до 100).\n",
    "  - Оптимизированы гиперпараметры с помощью Optuna (20 испытаний):\n",
    "    - `kernel`: тип ядра (`linear`, `rbf`, `poly`).\n",
    "    - `C`: регуляризация (1e-3–1e3, логарифмическая шкала).\n",
    "    - `gamma`: параметр ядра для `rbf` и `poly` (1e-4–1e1, логарифмическая шкала).\n",
    "  - Целевая метрика: F1 на валидационной выборке.\n",
    "- **Результаты**:\n",
    "  - Лучшие гиперпараметры: `k=64`, `kernel='linear'`, `C=0.02674`.\n",
    "  - Лучшая F1-метрика на валидационной выборке: **0.94772**.\n",
    "\n",
    "**4. Выбор модели и тестирование**\n",
    "- **Выбор модели**:\n",
    "  - На основе валидационной F1-метрики выбрана модель **LogisticRegression** с параметрами: `C=0.05949`, `solver='liblinear'`, `max_iter=857`, `penalty='l2'`, так как она показала наивысший результат (F1 = 0.95029).\n",
    "- **Тестирование**:\n",
    "  - Модель обучена на тренировочной выборке (`X_train`, `y_train`).\n",
    "  - Оценка на тестовой выборке (`X_test`, `y_test`): F1-метрика = **0.95034**.\n",
    "- **Вывод**:\n",
    "  - Логистическая регрессия продемонстрировала высокую производительность и стабильность на тестовой выборке, подтверждая качество подбора гиперпараметров.\n",
    "  - Модели LightGBM и SVC показали близкие результаты, но уступили по F1-метрике."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89610c72",
   "metadata": {},
   "source": [
    "# Итоговы вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4698e9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "В рамках проекта для интернет-магазина «Викишоп» была разработана модель машинного обучения для классификации комментариев на позитивные и негативные с целью выявления токсичных текстов для последующей модерации. Целью было достижение метрики F1 не менее 0.75. Работа выполнялась с использованием предобученной модели BERT (`unitary/toxic-bert`) и включала следующие этапы:\n",
    "\n",
    "1. **Загрузка и изучение данных**  \n",
    "   Данные из файла `toxic_comments.csv` содержали текст комментариев (столбец `text`) и целевой признак токсичности (столбец `toxic`). На этапе изучения подтверждена корректность структуры данных, отсутствие пропусков и необходимость предобработки текстов для дальнейшего анализа.\n",
    "\n",
    "2. **Предобработка данных**  \n",
    "   - Тексты токенизированы с использованием `BertTokenizer` (максимальная длина — 512 токенов, с добавлением специальных токенов и усечением).  \n",
    "   - Созданы эмбеддинги текстов с помощью модели `unitary/toxic-bert`, оптимизированной для задачи определения токсичности. Процесс выполнялся на GPU для ускорения, с извлечением эмбеддингов для токена `[CLS]` в батчах (размер батча — 100).  \n",
    "\n",
    "\n",
    "5. **Обучение моделей**  \n",
    "   - Рассмотрены три модели: **LogisticRegression**, **LightGBM** и **SVC**, с оптимизацией гиперпараметров через библиотеку Optuna .  \n",
    "   - **LogisticRegression**: Лучшая модель с гиперпараметрами `C=0.05949`, `solver='liblinear'`, `max_iter=857`, `penalty='l2'` показала F1 = **0.95029** на валидационной выборке и F1 = **0.95034** на тестовой выборке.  \n",
    "   - Выбрана модель **LogisticRegression** как наиболее производительная и стабильная, удовлетворяющая целевому порогу F1 ≥ 0.75.\n",
    "\n",
    "**Итоговые выводы и рекомендации**:  \n",
    "- Разработанная модель на основе логистической регрессии с эмбеддингами BERT (`unitary/toxic-bert`) успешно решает задачу классификации токсичных комментариев, демонстрируя высокую точность (F1 = 0.95034 на тестовой выборке).  \n",
    "- Использование предобученной модели BERT позволило эффективно извлечь информативные признаки из текстов, а оптимизация гиперпараметров через Optuna обеспечила выбор наилучших параметров.  \n",
    "- Модель готова к внедрению в систему модерации «Викишоп» для автоматического выявления токсичных комментариев.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
