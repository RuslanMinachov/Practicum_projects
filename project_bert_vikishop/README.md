<xaiArtifact artifact_id="e8455871-28e5-4ce1-a084-7005a2e82b84" artifact_version_id="15f9ddd2-fe54-4709-afe9-edd892675f1c" title="README.md" contentType="text/markdown">

# Классификация токсичных комментариев с использованием BERT

## Описание проекта

Интернет-магазин «Викишоп» внедряет новый сервис, позволяющий пользователям редактировать и дополнять описания товаров в стиле вики-сообществ. Пользователи могут предлагать правки и комментировать изменения других. Для обеспечения качества контента требуется инструмент автоматического выявления токсичных комментариев для их последующей модерации. Цель проекта — разработать модель машинного обучения для классификации комментариев на позитивные и негативные с метрикой качества F1 не менее 0.75. В проекте используется предобученная модель BERT (unitary/toxic-bert) для создания эмбеддингов текстов и различные алгоритмы машинного обучения для классификации.

## Задачи проекта

1. Загрузить и изучить данные из файла `toxic_comments.csv`.
2. Выполнить предобработку текстовых данных, включая токенизацию и создание эмбеддингов с использованием модели BERT.
3. Подготовить данные для обучения моделей.
4. Обучить и сравнить несколько моделей машинного обучения.
5. Выбрать лучшую модель на основе метрики F1 и протестировать её на тестовой выборке.
6. Сформулировать итоговые выводы.

## Исходные данные

- Данные находятся в файле `/datasets/toxic_comments.csv`.
- **Столбец `text`**: текст комментария.
- **Столбец `toxic`**: целевой признак (0 — позитивный, 1 — токсичный).

## Используемые библиотеки

numpy, pandas, torch, transformers, sklearn, optuna, lightgbm 

## Результаты работы

### Общие результаты
- Разработана модель для классификации токсичных комментариев для интернет-магазина «Викишоп».
- Данные из файла `toxic_comments.csv` содержат текст комментариев и метки токсичности (0 или 1).
- Подтверждена корректность структуры данных, пропуски отсутствуют.

### Предобработка данных
- Тексты токенизированы с использованием `BertTokenizer` (максимальная длина — 512 токенов, с добавлением специальных токенов и усечением).
- Созданы эмбеддинги текстов с помощью модели `unitary/toxic-bert`, оптимизированной для задачи определения токсичности.
- Эмбеддинги извлечены для токена `[CLS]` в батчах (размер батча — 100) с использованием GPU для ускорения.

### Обучение моделей
- Рассмотрены три модели: `LogisticRegression`, `LightGBM` и `SVC`.
- Гиперпараметры оптимизированы с использованием библиотеки `Optuna`.
- **Лучшая модель**: `LogisticRegression` с гиперпараметрами:
  - `C=0.05949`
  - `solver='liblinear'`
  - `max_iter=857`
  - `penalty='l2'`
- **Метрики**:
  - F1 на валидационной выборке: 0.95029
  - F1 на тестовой выборке: 0.95034
- Модель удовлетворяет целевому порогу F1 ≥ 0.75.

## Итоговые выводы и рекомендации
- Разработанная модель на основе логистической регрессии с эмбеддингами `unitary/toxic-bert` успешно решает задачу классификации токсичных комментариев, демонстрируя высокую точность (F1 = 0.95034 на тестовой выборке).
- Использование предобученной модели BERT позволило эффективно извлечь информативные признаки из текстов, а оптимизация гиперпараметров через `Optuna` обеспечила выбор наилучших параметров.
- Модель готова к внедрению в систему модерации «Викишоп» для автоматического выявления токсичных комментариев.
- **Рекомендации**:
  - Периодически обновлять модель с учетом новых данных для поддержания высокой точности.
  - Рассмотреть возможность дообучения модели BERT на специфичных данных магазина для повышения производительности.

</xaiArtifact>
